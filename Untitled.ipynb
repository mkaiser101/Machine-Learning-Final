{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.513</td>\n",
       "      <td>92000000.0</td>\n",
       "      <td>0.2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.558</td>\n",
       "      <td>23000000.0</td>\n",
       "      <td>0.4140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.777</td>\n",
       "      <td>129000000.0</td>\n",
       "      <td>0.3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.779</td>\n",
       "      <td>85400000.0</td>\n",
       "      <td>0.3910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.516</td>\n",
       "      <td>132000000.0</td>\n",
       "      <td>0.5560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>189</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.622</td>\n",
       "      <td>30800000.0</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>189</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.487</td>\n",
       "      <td>60800000.0</td>\n",
       "      <td>0.7610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>189</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.880</td>\n",
       "      <td>2430000.0</td>\n",
       "      <td>0.7160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>189</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.851</td>\n",
       "      <td>14100000.0</td>\n",
       "      <td>0.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>189</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.880</td>\n",
       "      <td>2430000.0</td>\n",
       "      <td>0.7160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>247</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.799</td>\n",
       "      <td>29600000.0</td>\n",
       "      <td>0.5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>247</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.908</td>\n",
       "      <td>28400000.0</td>\n",
       "      <td>0.9190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>247</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.621</td>\n",
       "      <td>25900000.0</td>\n",
       "      <td>0.4280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>247</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.545</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>0.5060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>247</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.645</td>\n",
       "      <td>18000000.0</td>\n",
       "      <td>0.5950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4421</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.661</td>\n",
       "      <td>171000000.0</td>\n",
       "      <td>0.3350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4421</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.687</td>\n",
       "      <td>290000000.0</td>\n",
       "      <td>0.6680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4421</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.843</td>\n",
       "      <td>102000000.0</td>\n",
       "      <td>0.7430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4421</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.252</td>\n",
       "      <td>132000000.0</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4421</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.857</td>\n",
       "      <td>175000000.0</td>\n",
       "      <td>0.6880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3514</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.567</td>\n",
       "      <td>322000000.0</td>\n",
       "      <td>0.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3514</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.714</td>\n",
       "      <td>70400000.0</td>\n",
       "      <td>0.5540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3514</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.530</td>\n",
       "      <td>138000000.0</td>\n",
       "      <td>0.3670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3514</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.435</td>\n",
       "      <td>17400000.0</td>\n",
       "      <td>0.0849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3514</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.734</td>\n",
       "      <td>294000000.0</td>\n",
       "      <td>0.4250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2            3       4\n",
       "0    199  0.796  0.513   92000000.0  0.2350\n",
       "1    199  0.704  0.558   23000000.0  0.4140\n",
       "2    199  0.695  0.777  129000000.0  0.3600\n",
       "3    199  0.834  0.779   85400000.0  0.3910\n",
       "4    199  0.841  0.516  132000000.0  0.5560\n",
       "5    189  0.500  0.622   30800000.0  0.2520\n",
       "6    189  0.828  0.487   60800000.0  0.7610\n",
       "7    189  0.552  0.880    2430000.0  0.7160\n",
       "8    189  0.422  0.851   14100000.0  0.6670\n",
       "9    189  0.552  0.880    2430000.0  0.7160\n",
       "10   247  0.729  0.799   29600000.0  0.5320\n",
       "11   247  0.820  0.908   28400000.0  0.9190\n",
       "12   247  0.681  0.621   25900000.0  0.4280\n",
       "13   247  0.685  0.545   16000000.0  0.5060\n",
       "14   247  0.488  0.645   18000000.0  0.5950\n",
       "15  4421  0.394  0.661  171000000.0  0.3350\n",
       "16  4421  0.869  0.687  290000000.0  0.6680\n",
       "17  4421  0.680  0.843  102000000.0  0.7430\n",
       "18  4421  0.598  0.252  132000000.0  0.0352\n",
       "19  4421  0.756  0.857  175000000.0  0.6880\n",
       "20  3514  0.770  0.567  322000000.0  0.2600\n",
       "21  3514  0.745  0.714   70400000.0  0.5540\n",
       "22  3514  0.789  0.530  138000000.0  0.3670\n",
       "23  3514  0.487  0.435   17400000.0  0.0849\n",
       "24  3514  0.822  0.734  294000000.0  0.4250"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Book1.csv',header = None)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "\n",
    "Y_train = df.iloc[0:, 1].values\n",
    "text_train = df.iloc[0:, 4].values\n",
    "\n",
    "#Y_test = df_test.iloc[0:, 1].values\n",
    "#text_test = df_test.iloc[0:, 4].values\n",
    "\n",
    "X = df.values[:, 1:4]\n",
    "Y = df.values[0:,0]\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def ngrams(tokens, n):\n",
    "    output = []\n",
    "    for i in range(n-1, len(tokens)):\n",
    "        ngram = ' '.join(tokens[i-n+1:i+1])\n",
    "        output.append(ngram)\n",
    "    return output\n",
    "\n",
    "def features(text, ngram_range=(1,1)):\n",
    "    text = text.lower()      # make the string lowercase\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)     # remove consecutive characters that are repeated more than twice\n",
    "    \n",
    "    features_in_text = []   # running list of all features in this instance (can be repeated)\n",
    "    \n",
    "    # treat alphanumeric characters as word tokens (removing anything else),\n",
    "    # and extract all n-grams of length n specified by ngram_range\n",
    "    \n",
    "    text_alphanum = re.sub('[^a-z0-9]', ' ', text)\n",
    "    for n in range(ngram_range[0], ngram_range[1]+1):\n",
    "        features_in_text += ngrams(text_alphanum.split(), n)\n",
    "    \n",
    "    # now treat punctuation as word tokens, and get their counts (only unigrams)\n",
    "    \n",
    "    text_punc = re.sub('[a-z0-9]', ' ', text)\n",
    "    features_in_text += ngrams(text_punc.split(), 1)\n",
    "    \n",
    "    # 'Counter' converts a list into a dictionary whose keys are the list elements \n",
    "    #  and the values are the number of times each element appeared in the list\n",
    "    \n",
    "    return Counter(features_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matt\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter settings: {'C': 0.01}\n",
      "Validation accuracy: 0.052632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# this defines the classifier we will use -- don't change this variable\n",
    "\n",
    "base_classifier = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=123)\n",
    "\n",
    "# these are the C values we will compare -- don't change this variable\n",
    "\n",
    "params = [{'C': [0.01, 0.1, 0.5, 1.0, 2.5, 5.0, 10.0, 50.0, 100.0]}]\n",
    "\n",
    "# this performs 5-fold cross-validation with the above classifier and parameter options\n",
    "\n",
    "gs_classifier = GridSearchCV(base_classifier, params, cv=5)\n",
    "gs_classifier.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best parameter settings:\", gs_classifier.best_params_)\n",
    "print(\"Validation accuracy: %0.6f\" % gs_classifier.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100)\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "tree.export_graphviz(clf_entropy, out_file='ttt.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
